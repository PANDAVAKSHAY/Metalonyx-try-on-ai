import { GoogleGenAI, Modality } from "@google/genai";
import { UploadedFile } from '../types';

const fileToGenerativePart = async (file: File) => {
  const base64EncodedDataPromise = new Promise<string>((resolve) => {
    const reader = new FileReader();
    reader.onloadend = () => {
      if (typeof reader.result === 'string') {
        resolve(reader.result.split(',')[1]);
      }
    };
    reader.readAsDataURL(file);
  });
  const base64EncodedData = await base64EncodedDataPromise;
  return {
    inlineData: {
      data: base64EncodedData,
      mimeType: file.type,
    },
  };
};

const buildPrompt = (hasCad: boolean): string => {
  let prompt = `
    Task: Create an ultra-realistic virtual try-on image.
    
    Base Image: The first image provided is the model. Do not alter the model's appearance, pose, or the background.
    
    Jewelry Images: The subsequent images show a piece of jewelry from multiple angles.
    
    Instructions:
    1. Analyze the model image to identify a suitable placement area (neck for a necklace, ear for an earring, hand/finger for a ring).
    2. Analyze the jewelry images to understand its form, material, texture, and how it should be worn.
    3. Realistically place the jewelry onto the model.
    4. Integrate the jewelry seamlessly. This includes:
       - Creating accurate and soft shadows based on the lighting in the model's photo.
       - Generating realistic reflections on the jewelry's surface that match the environment.
       - Ensuring the color tone and lighting on the jewelry perfectly match the base image.
  `;

  if (hasCad) {
    prompt += `
    5. A CAD image is provided with dimensional details. Use this as a reference to ensure the jewelry is scaled accurately on the model.
    `;
  }

  prompt += `
    Output: A single, high-resolution, photorealistic 4K image. The final image should look like a real photograph, not a composite.
  `;
  return prompt;
};

export const generateTryOnImage = async (
  modelImage: UploadedFile,
  jewelryImages: UploadedFile[],
  cadImage: UploadedFile | null
): Promise<string> => {
  if (!process.env.API_KEY) {
    throw new Error("API_KEY environment variable is not set.");
  }
  const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

  const prompt = buildPrompt(!!cadImage);
  
  const modelPart = await fileToGenerativePart(modelImage.file);
  const jewelryParts = await Promise.all(jewelryImages.map(img => fileToGenerativePart(img.file)));
  const cadPart = cadImage ? await fileToGenerativePart(cadImage.file) : null;

  const allParts = [
    { text: prompt },
    modelPart,
    ...jewelryParts,
  ];
  if (cadPart) {
    allParts.push(cadPart);
  }

  const response = await ai.models.generateContent({
    model: 'gemini-2.5-flash-image',
    contents: {
      parts: allParts,
    },
    config: {
        responseModalities: [Modality.IMAGE],
    },
  });

  for (const part of response.candidates[0].content.parts) {
    if (part.inlineData) {
      const base64ImageBytes: string = part.inlineData.data;
      return `data:${part.inlineData.mimeType};base64,${base64ImageBytes}`;
    }
  }

  throw new Error("No image was generated by the API.");
};
